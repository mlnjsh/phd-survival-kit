# How to Choose the Right Journal

> **Choosing the wrong journal is one of the most common and costly mistakes in academic publishing.** A poor choice can mean 6--12 months wasted on a desk rejection, followed by reformatting and resubmitting elsewhere. This guide helps you make an informed decision.

---

## Step 1: Understand Indexing and Rankings

### Journal Indexing Categories

| Index | What It Means | Prestige Level | Who Cares |
|-------|---------------|----------------|-----------|
| **SCI (SCIE)** | Science Citation Index (Expanded), maintained by Clarivate (Web of Science) | High | Tenure committees, funding agencies worldwide |
| **Scopus** | Elsevier's citation database, broader coverage than WoS | Medium--High | Many institutions accept Scopus-indexed publications |
| **PubMed/MEDLINE** | Biomedical literature database by NIH | High (for bio/medical) | Medical and health science researchers |
| **ESCI** | Emerging Sources Citation Index (newer tier of Web of Science) | Medium | Shows the journal is being evaluated for SCIE |
| **DOAJ** | Directory of Open Access Journals | Varies | Validates open access journals as legitimate |
| **UGC-CARE List** | University Grants Commission approved (India) | Required in India | Indian academics for career advancement |

### Impact Factor and Alternatives

| Metric | What It Measures | Published By | Pros | Cons |
|--------|-----------------|-------------|------|------|
| **Journal Impact Factor (JIF)** | Avg citations per article in last 2 years | Clarivate (Web of Science) | Widely recognized, standardized | Field-dependent, gameable, 2-year window is short |
| **CiteScore** | Avg citations per article in last 4 years | Scopus/Elsevier | Broader window, transparent | Less universally recognized than JIF |
| **SJR (SCImago)** | Weighted citation metric (quality of citing journals matters) | SCImago | Accounts for citation quality | Complex to interpret |
| **SNIP** | Normalizes for citation potential by field | CWTS Leiden | Fair cross-field comparison | Less well known |
| **h5-index** | h-index of articles published in last 5 years | Google Scholar | Easy to check, broad coverage | No quality control on sources |

> **Tip:** Never evaluate a journal by impact factor alone. A 2.0 IF journal in pure mathematics is excellent; a 2.0 IF journal in biomedical sciences is below average. Always compare within your specific field.

---

## Step 2: Match Your Paper to the Journal

### Scope Alignment

This is the number one reason for desk rejections. Ask:

- [ ] Does the journal publish papers on your specific topic?
- [ ] Check the journal's **Aims and Scope** page (not just the title)
- [ ] Look at papers published in the last 2--3 issues --- does your paper fit alongside them?
- [ ] Does the journal publish your type of paper (theoretical, empirical, survey, short communication)?
- [ ] Is your paper's length within the journal's typical range?

### Audience Alignment

- **Specialist journals** (e.g., *Journal of Topology*, *Pattern Recognition Letters*): Your audience knows the field deeply. You can assume background knowledge.
- **Broad journals** (e.g., *Nature*, *Science*, *IEEE TPAMI*): Your audience is diverse. The paper must be more accessible.
- **Interdisciplinary journals** (e.g., *PLOS ONE*, *Scientific Reports*): Your paper should emphasize broad impact and be understandable across disciplines.

---

## Step 3: Evaluate the Journal

### Key Factors to Research

| Factor | How to Check | What to Look For |
|--------|-------------|-----------------|
| **Scope match** | Read Aims & Scope; browse recent issues | Direct relevance to your topic |
| **Impact Factor / CiteScore** | Journal website, JCR, Scopus | Appropriate for your paper's quality |
| **Acceptance rate** | Journal website, SCImago, ask colleagues | 10--30% for competitive journals |
| **Review timeline** | Journal website, Publons reviews | Average time from submission to first decision |
| **Publication timeline** | Check "Received/Accepted/Published" dates on recent articles | Time from acceptance to online publication |
| **Open Access options** | Journal website | Gold OA fees (APCs), green OA allowed? |
| **Predatory risk** | Beall's List, Think.Check.Submit, DOAJ | Verify legitimacy |
| **Indexing** | Journal website, Master Journal List (WoS), Scopus Sources | Confirm claimed indexing is real |
| **Publisher reputation** | Publisher website | IEEE, Springer, Elsevier, Wiley, ACM, etc. are reputable |

### Where to Check These Factors

- **Clarivate Master Journal List:** mjl.clarivate.com (verify SCIE/ESCI indexing)
- **Scopus Source List:** scopus.com/sources (verify Scopus indexing)
- **SCImago Journal Rank:** scimagojr.com (free IF alternative, journal rankings by category)
- **Google Scholar Metrics:** scholar.google.com/citations?view_op=top_venues (h5-index rankings)
- **Publons / Web of Science:** publons.com (review timelines, editor response times)
- **Sherpa Romeo:** sherpa.ac.uk/romeo (open access policies by journal)
- **Think.Check.Submit:** thinkchecksubmit.org (predatory journal screening)

---

## Step 4: Comparative Journal Selection Table

Create a table like this for your top 3--5 candidate journals:

| Criterion | Journal A | Journal B | Journal C |
|-----------|-----------|-----------|-----------|
| **Full name** | IEEE Trans. Pattern Anal. Mach. Intell. | Pattern Recognition | Neurocomputing |
| **Publisher** | IEEE | Elsevier | Elsevier |
| **Impact Factor** | 20.8 | 8.0 | 5.5 |
| **CiteScore** | 38.2 | 16.5 | 10.1 |
| **SCI/Scopus** | SCI (Q1) | SCI (Q1) | SCI (Q2) |
| **Scope match** | Excellent | Good | Good |
| **Acceptance rate** | ~8% | ~18% | ~30% |
| **Avg review time** | 3--6 months | 2--4 months | 1--3 months |
| **Open access APC** | $2,995 | $3,390 | $2,890 |
| **Page limit** | 14 pages | No strict limit | No strict limit |
| **Predatory risk** | None | None | None |
| **My assessment** | Stretch goal | Strong fit | Safe option |

---

## Step 5: The Tier Strategy

Rank your candidate journals into tiers:

**Tier 1 (Dream):** The best journal where your paper could realistically be published. High IF, high prestige. Accept a longer review time and lower acceptance rate.

**Tier 2 (Target):** A strong, respected journal where your paper is a solid fit. This is usually where you should submit first.

**Tier 3 (Backup):** A reliable journal with good indexing and reasonable acceptance rates. Use this if Tier 2 rejects.

> **Strategy:** Submit to your Tier 2 journal first, not Tier 1. A Tier 1 rejection followed by a Tier 2 submission can take 12+ months. If you get desk-rejected from Tier 2, move to Tier 3 quickly. If you get good reviews at Tier 2 with a revise-and-resubmit, take it seriously --- that is the path to publication.

---

## Step 6: Avoiding Predatory Journals

Predatory journals exploit the publish-or-perish pressure by charging fees without providing legitimate peer review.

### Red Flags

- [ ] Unsolicited emails inviting you to submit (real journals do not spam)
- [ ] Promises of very fast review (2--3 weeks for a journal paper is suspicious)
- [ ] Journal title is confusingly similar to a reputable journal
- [ ] No clearly identified editorial board, or board members are unverifiable
- [ ] Journal is not indexed in Web of Science or Scopus (but claims to be)
- [ ] Article Processing Charges (APCs) are unusually low or hidden
- [ ] The journal publishes papers across wildly unrelated fields
- [ ] Poor grammar on the journal website itself
- [ ] No retraction policy or publication ethics statement

### Verification Steps

1. Check the **Clarivate Master Journal List** for SCIE/ESCI indexing
2. Check the **Scopus Source List** for Scopus indexing
3. Verify the journal on **DOAJ** if it claims to be open access
4. Use **Think.Check.Submit** (thinkchecksubmit.org) as a decision tool
5. Ask your advisor and senior colleagues if they know the journal

> **Rule of thumb:** If you have never heard of the journal and it emails you first, it is probably predatory.

---

## Journal vs. Conference: When to Choose Which

| Factor | Journal | Conference |
|--------|---------|------------|
| **Review quality** | Typically more thorough, multiple rounds | Single round, sometimes rushed |
| **Timeline** | 6--18 months from submission to publication | 3--6 months from submission to presentation |
| **Page limit** | Often unlimited or generous (12--20+ pages) | Strict (8--10 pages typical) |
| **Revision opportunity** | Usually major/minor revision before accept/reject | Accept or reject (no revision round) |
| **Prestige (CS)** | Varies; some top conferences outrank most journals | Top conferences (NeurIPS, ICML, CVPR) are very prestigious in CS |
| **Prestige (other fields)** | Generally higher than conferences | Generally lower than journals |
| **Networking** | No presentation required | Presentation and networking opportunity |
| **Impact Factor** | Yes | No (conferences have h5-index) |
| **Best for** | Complete, polished, comprehensive work | Timely results, early ideas, visibility |

---

## Sample Journal Lists by Field

### Computer Vision / Image Processing

| Journal | IF (approx.) | Quartile | Notes |
|---------|-------------|----------|-------|
| IEEE Trans. PAMI | ~21 | Q1 | Top journal in the field |
| Int. J. Computer Vision | ~12 | Q1 | Highly competitive |
| IEEE Trans. Image Processing | ~10 | Q1 | Strong IP focus |
| Pattern Recognition | ~8 | Q1 | Broad scope |
| Computer Vision and Image Understanding | ~4.5 | Q1 | Solid mid-tier |
| Pattern Recognition Letters | ~3.5 | Q2 | Good for shorter contributions |
| Neurocomputing | ~5.5 | Q2 | ML/neural network focus |

### Machine Learning / AI

| Journal | IF (approx.) | Quartile | Notes |
|---------|-------------|----------|-------|
| J. Machine Learning Research | ~6 | Q1 | Open access, highly regarded |
| IEEE Trans. Neural Networks and Learning Systems | ~10 | Q1 | Strong ML journal |
| Machine Learning (Springer) | ~5 | Q1 | Foundational journal |
| Artificial Intelligence (Elsevier) | ~5.1 | Q1 | Broad AI scope |
| Neural Networks | ~6 | Q1 | Neural network focus |

---

## Decision-Making Checklist

Before submitting, answer YES to all of these:

- [ ] The journal's scope explicitly covers my paper's topic
- [ ] My paper's quality matches the journal's standards (based on recent publications)
- [ ] The journal is indexed in SCI/Scopus (or I have a specific reason for choosing a non-indexed venue)
- [ ] I have verified the journal is not predatory
- [ ] The review timeline is acceptable given my career needs
- [ ] I can afford the APC if the journal charges one (or my institution covers it)
- [ ] My advisor agrees with the choice
- [ ] I have a backup journal identified in case of rejection

---

> **Final thought:** There is no perfect journal for any paper. There is a range of appropriate journals, and any of them could be the right choice. What matters most is scope alignment and honest quality assessment. Do not waste time chasing prestige beyond what your paper merits, and do not undersell your work by aiming too low out of impatience.
